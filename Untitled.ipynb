{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43253df-5d68-4f16-870f-3a141f669c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leoguinan/Library/Caches/pypoetry/virtualenvs/backend-hNkkeHAR-py3.12/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "from asgiref.sync import sync_to_async\n",
    "from prelo.models import PitchDeck\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from decouple import config\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser, JsonKeyOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from submind.tasks import think, chat, complete_goals, complete_goal,create_structure\n",
    "from submind.models import Goal,Submind\n",
    "import uuid\n",
    "from submind.llms.submind import SubmindModelFactory\n",
    "from submind.memory.memory import remember\n",
    "from submind.models import Conversation, Message \n",
    "\n",
    "\n",
    "deck = PitchDeck.objects.get(id=27)\n",
    "combined = \"\"\n",
    "\n",
    "for slide in deck.slides.order_by(\"order\"):\n",
    "    if slide.order != 17:\n",
    "        combined += f\"Page {slide.order}:\\n{slide.content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e037a0-2fcb-4fb1-a48e-3eb29e29bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submind = Submind.objects.get(id=440)\n",
    "\n",
    "# now, need to start having conversations. Can start with the think method, and break it down from there.\n",
    "\"\"\"\n",
    "Think about a goal\n",
    "\"\"\"\n",
    "\n",
    "topic = \"What do early stage investors value in a pitch deck?\"\n",
    "\n",
    "#JIT conversation created.\n",
    "\n",
    "START_CONVERSATION_PROMPT = \"\"\"You are a powerful submind that is focused on {description}.\n",
    "You have your own subminds that you can communicate with.\n",
    "\n",
    "Here are the subminds you currently have:\n",
    "{subminds}\n",
    "\n",
    "Here is the current topic you want to know more about: {topic}\n",
    "\n",
    "Here's what you currently know: {mind}\n",
    "\n",
    "Based on what you know and the subminds you have access to talk to, which subminds do you want to have a conversation with?\n",
    "\n",
    "And what topics would you like to discuss with that submind?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "CAN_I_HELP_PROMPT = \"\"\"\n",
    "\n",
    "You are a powerful submind that is focused on {description}.\n",
    "You have your own subminds that you can communicate with.\n",
    "\n",
    "Here are the subminds you currently have:\n",
    "{subminds}\n",
    "\n",
    "Here is the current topic a submind wants to talk about: {topic}\n",
    "\n",
    "Here's what you currently know: {mind}\n",
    "\n",
    "Based on what you know and the subminds you have access to talk to, is this something you are confident that you can help with?\n",
    "\"\"\"\n",
    "\n",
    "SUBMIND_CONVERSATION_RESPONSE = \"\"\"\n",
    "\n",
    "You are a powerful submind that is focused on {description}.\n",
    "\n",
    "Here is the current topic another submind wants to talk about: {topic}\n",
    "\n",
    "Here's what you currently know: {mind}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"start_conversations\",\n",
    "        \"description\": \"decide which subminds to start conversations with\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"conversations\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"which conversations to have\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"submind_id\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The id of the submind you want to have a conversation with.\",\n",
    "                                \n",
    "                            },\n",
    "                            \"conversation_topic\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"A summary of what you are researching and why you think it would be helpful for the user.\"\n",
    "                            }\n",
    "\n",
    "                        }\n",
    "                        \n",
    "\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"conversations\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"can_I_help\",\n",
    "        \"description\": \"decide whether or not you are able to respond to the request knowledgably\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"can_i_help\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"description\": \"am I able to help with this request\",\n",
    "                   \n",
    "                   \n",
    "\n",
    "                    \n",
    "            },\n",
    "        },\n",
    "            \"required\": [\"can_i_help\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a3adea-defa-4a9f-82cd-aacc30ad5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_convo(base_submind, topic, previous_conversation_id=None):\n",
    "    model = SubmindModelFactory.get_model(base_submind.uuid, \"start_conversation\")\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(START_CONVERSATION_PROMPT)\n",
    "    chain = prompt | model.bind(function_call={\"name\": \"start_conversations\"},\n",
    "                                functions=functions) | JsonOutputFunctionsParser()\n",
    "    \n",
    "    mind = remember(base_submind)\n",
    "    \n",
    "    prepped_subminds = []\n",
    "    for child in base_submind.subminds.all():\n",
    "        prepped_subminds.append(\n",
    "            f\"Submind -- Id: {child.id} -- Name: {child.name} -- Description: {child.description}\")\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\"description\": base_submind.description,\n",
    "         \"subminds\": \"\\n\".join(prepped_subminds),\n",
    "         \"topic\":topic,\n",
    "         \"mind\": mind\n",
    "        })\n",
    "    \n",
    "    \n",
    "    print(response)\n",
    "\n",
    "    new_conversation = Conversation.objects.create(uuid=str(uuid.uuid4()), topic=topic,initiated_by=base_submind)\n",
    "    if previous_conversation_id:\n",
    "        previous_conversation = Conversation.objects.get(id=previous_conversation_id)\n",
    "        new_conversation.parent = previous_conversation\n",
    "        new_conversation.save()\n",
    "\n",
    "    messages = []\n",
    "    for conversation in response[\"conversations\"]:\n",
    "        try:\n",
    "            to_submind = Submind.objects.get(id=conversation[\"submind_id\"])\n",
    "            new_conversation.participants.add(to_submind)\n",
    "            new_conversation.save()\n",
    "            msg = Message.objects.create(uuid=str(uuid.uuid4()), content=conversation[\"conversation_topic\"], sender=base_submind, receiver=to_submind, conversation=new_conversation)\n",
    "            messages.append(msg)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error with submind id: {conversation.get(\"submind_id\", \"Missing submind id\")}\")\n",
    "            continue\n",
    "    return new_conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706cc193-003c-4765-903c-7abe237b392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submind -- Id: 441 -- Name: Prelo -- Description: Early-stage startup investing\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(prepped_subminds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf61cd12-3997-44c9-86bf-c202efcda45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversations': [{'submind_id': '441', 'conversation_topic': \"What do early stage investors value in a pitch deck? Exploring the key elements that attract early-stage investors to a startup's pitch deck.\"}]}\n"
     ]
    }
   ],
   "source": [
    "c = start_convo(submind, topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38834cd5-30d0-4ee1-be59-ce7e7aba9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 messages...\n",
      "\n",
      "\n",
      "receiving a message back, think I should learn something based on this\n",
      "What I knew before:\n",
      "\n",
      "\n",
      "\n",
      "Now learning...\n",
      "\n",
      "\n",
      "Beginning learning process\n",
      "Existing mind: \n",
      "New mind: You now know the key elements that early-stage investors value in a pitch deck, which include:\n",
      "\n",
      "1. **Clarity in Problem and Solution Presentation**: Clearly define the problem and how your solution uniquely addresses it.\n",
      "  \n",
      "2. **Data-Driven Market Analysis**: Use up-to-date, relevant market research to establish market opportunity and industry understanding.\n",
      "  \n",
      "3. **Compelling Product/Service Showcase**: Provide a detailed overview and demonstrate your product or service with visuals and real-world examples.\n",
      "  \n",
      "4. **Robust Business Model Explanation**: Articulate your business model, including revenue generation, cost structure, and scalability.\n",
      "  \n",
      "5. **In-depth Competitive Analysis**: Map out the competitive landscape and highlight your startup’s competitive advantages.\n",
      "  \n",
      "6. **Strategic Go-to-Market Plan**: Detail your market entry strategy, marketing and sales tactics, partnerships, and distribution channels.\n",
      "  \n",
      "7. **Team Experience and Expertise**: Highlight the strengths and relevant experiences of key team members.\n",
      "  \n",
      "8. **Realistic Financial Projections**: Include detailed financial forecasts with logical assumptions.\n",
      "  \n",
      "9. **Clear Exit Strategy**: Discuss potential exit strategies to show understanding of return on investment.\n",
      "  \n",
      "10. **Achievements and Future Milestones**: Outline past accomplishments and future growth targets.\n",
      "  \n",
      "11. **Highlight Innovation and IP**: Detail any proprietary technology or intellectual property and its protection.\n",
      "  \n",
      "12. **Risk and Compliance Awareness**: Acknowledge risks and compliance strategies.\n",
      "  \n",
      "13. **Engaging Presentation Style**: Craft a narrative with emotional engagement and maintain a professional, visually appealing design.\n",
      "  \n",
      "14. **Strategic and Economic Context**: Show awareness of broader economic and market trends and align your strategy accordingly.\n",
      "\n",
      "These points help in creating a pitch deck that resonates with early-stage investors, demonstrating the viability and strategic acumen of the business.\n",
      "Now I know kung fu! J/k. Here's what I know:\n",
      "\n",
      "\n",
      "You now know the key elements that early-stage investors value in a pitch deck, which include:\n",
      "\n",
      "1. **Clarity in Problem and Solution Presentation**: Clearly define the problem and how your solution uniquely addresses it.\n",
      "  \n",
      "2. **Data-Driven Market Analysis**: Use up-to-date, relevant market research to establish market opportunity and industry understanding.\n",
      "  \n",
      "3. **Compelling Product/Service Showcase**: Provide a detailed overview and demonstrate your product or service with visuals and real-world examples.\n",
      "  \n",
      "4. **Robust Business Model Explanation**: Articulate your business model, including revenue generation, cost structure, and scalability.\n",
      "  \n",
      "5. **In-depth Competitive Analysis**: Map out the competitive landscape and highlight your startup’s competitive advantages.\n",
      "  \n",
      "6. **Strategic Go-to-Market Plan**: Detail your market entry strategy, marketing and sales tactics, partnerships, and distribution channels.\n",
      "  \n",
      "7. **Team Experience and Expertise**: Highlight the strengths and relevant experiences of key team members.\n",
      "  \n",
      "8. **Realistic Financial Projections**: Include detailed financial forecasts with logical assumptions.\n",
      "  \n",
      "9. **Clear Exit Strategy**: Discuss potential exit strategies to show understanding of return on investment.\n",
      "  \n",
      "10. **Achievements and Future Milestones**: Outline past accomplishments and future growth targets.\n",
      "  \n",
      "11. **Highlight Innovation and IP**: Detail any proprietary technology or intellectual property and its protection.\n",
      "  \n",
      "12. **Risk and Compliance Awareness**: Acknowledge risks and compliance strategies.\n",
      "  \n",
      "13. **Engaging Presentation Style**: Craft a narrative with emotional engagement and maintain a professional, visually appealing design.\n",
      "  \n",
      "14. **Strategic and Economic Context**: Show awareness of broader economic and market trends and align your strategy accordingly.\n",
      "\n",
      "These points help in creating a pitch deck that resonates with early-stage investors, demonstrating the viability and strategic acumen of the business.\n"
     ]
    }
   ],
   "source": [
    "from submind.memory.memory import remember, learn\n",
    "\n",
    "model = SubmindModelFactory.get_model(submind.uuid, \"start_conversation\")\n",
    "prompt = ChatPromptTemplate.from_template(CAN_I_HELP_PROMPT)\n",
    "chain = prompt | model.bind(function_call={\"name\": \"can_I_help\"},\n",
    "                            functions=functions) | JsonOutputFunctionsParser()\n",
    "\n",
    "messages = Message.objects.filter(received=False).all()\n",
    "print(f\"Processing {len(messages)} messages...\\n\\n\")\n",
    "for message in messages:    \n",
    "    from_submind = message.sender\n",
    "    receiving_submind = message.receiver\n",
    "\n",
    "    if receiving_submind == message.conversation.initiated_by:\n",
    "        print(\"receiving a message back, think I should learn something based on this\")\n",
    "        print(\"What I knew before:\\n\\n\")\n",
    "        receiving_mind = remember(receiving_submind)\n",
    "        print(receiving_mind)\n",
    "        print(\"Now learning...\\n\\n\")\n",
    "        learn({\"question\": message.conversation.topic, \"answer\": message.content }, receiving_submind)\n",
    "        print(\"Now I know kung fu! J/k. Here's what I know:\\n\\n\")\n",
    "        receiving_mind = remember(receiving_submind)\n",
    "        print(receiving_mind)\n",
    "        message.received = True\n",
    "        message.save()\n",
    "        # do I need to learn anything else from this submind? For now, let's assume no. We'll stop here and move to the next one.\n",
    "        continue\n",
    "    \n",
    "    receiving_mind = remember(receiving_submind)\n",
    "    prepped_subminds = []\n",
    "    for child in receiving_submind.subminds.all():\n",
    "        prepped_subminds.append(\n",
    "            f\"Submind -- Id: {child.id} -- Name: {child.name} -- Description: {child.description}\")\n",
    "    print(f\"Available Subminds: \\n {\"\\n\".join(prepped_subminds)}\")\n",
    "    response = chain.invoke(\n",
    "        {\"description\": receiving_submind.description,\n",
    "         \"subminds\": \"\\n\".join(prepped_subminds),\n",
    "         \"topic\":message.content,\n",
    "         \"mind\": receiving_mind\n",
    "        })\n",
    "    \n",
    "    if response['can_i_help']:\n",
    "        print(f\"I can help, according to {response}\")\n",
    "        print(f\"Receiving submind, submind {receiving_submind.name}, has {len(prepped_subminds)} children. Delegating...\\n\\n\")\n",
    "        if len(prepped_subminds) == 0:\n",
    "            print(\"responding...\\n\\n\")\n",
    "            # determine whether or not should try to learn or should answer from memory. Alternate question: how much do I actually need to learn? Or at this level, is simply the specificity enought?\n",
    "            respond_prompt = ChatPromptTemplate.from_template(SUBMIND_CONVERSATION_RESPONSE)\n",
    "            response_chain = respond_prompt | model | StrOutputParser()\n",
    "            answer = response_chain.invoke(\n",
    "                {\"description\": receiving_submind.description,\n",
    "                 \"topic\":message.content,\n",
    "                 \"mind\": receiving_mind\n",
    "                })\n",
    "            print(answer)\n",
    "            Message.objects.create(uuid=str(uuid.uuid4()), content=answer, sender=receiving_submind, receiver=from_submind, conversation=message.conversation)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(f\"Starting a new conversation with children\")\n",
    "            passed_along = start_convo(receiving_submind, message.content, message.conversation.id)\n",
    "    else:\n",
    "        print(\"Can't help, bailing...\\n\\n\")\n",
    "            \n",
    "    message.received = True\n",
    "    message.save()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "91fe7126-9508-49c2-8d09-a3f3b3bee1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 12 conversations to finalize...\n",
      "\n",
      "\n",
      "Looks like conversation 43 hasn't received any messages yet from 441...\n",
      "\n",
      "\n",
      "Looks like conversation 50 hasn't received any messages yet from 441...\n",
      "\n",
      "\n",
      "Looks like conversation 44 hasn't received any messages yet from 442...\n",
      "\n",
      "\n",
      "Looks like conversation 51 hasn't received any messages yet from 446...\n",
      "\n",
      "\n",
      "Looks like conversation 37 hasn't received any messages yet from 442...\n",
      "\n",
      "\n",
      "Checking blocking conversation 55 to see if finished...\n",
      "Looks like conversation 38 hasn't received any messages yet from 443...\n",
      "\n",
      "\n",
      "Looks like conversation 39 hasn't received any messages yet from 447...\n",
      "\n",
      "\n",
      "Looks like conversation 40 hasn't received any messages yet from 452...\n",
      "\n",
      "\n",
      "Looks like conversation 41 hasn't received any messages yet from 457...\n",
      "\n",
      "\n",
      "Looks like conversation 42 hasn't received any messages yet from 462...\n",
      "\n",
      "\n",
      "Looks like conversation 36 hasn't received any messages yet from 441...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversations_to_finalize = Conversation.objects.filter(completed=False).all()\n",
    "print(f\"found {len(conversations_to_finalize)} conversations to finalize...\\n\\n\")\n",
    "for conversation in conversations_to_finalize:\n",
    "    finished = True\n",
    "    for blocking in conversation.blocked_by.all():\n",
    "        print(f\"Checking blocking conversation {blocking.id} to see if finished...\")\n",
    "        if not blocking.completed:\n",
    "            print(\"Not finished, bailing...\")\n",
    "            finished = False\n",
    "    if not finished:\n",
    "        continue\n",
    "    for participant in conversation.participants.all():\n",
    "        received_from = Message.objects.filter(conversation=conversation, sender=participant).first()\n",
    "        if not received_from:\n",
    "            print(f\"Looks like conversation {conversation.id} hasn't received any messages yet from {participant.id}...\\n\\n\")\n",
    "            finished=False\n",
    "            break\n",
    "    if not finished:\n",
    "        continue\n",
    "    # ok, at this point, we know this conversation is finished. So we have learned from all the sub conversations and need to see if this is blocking any upstairs conversations, and respond to that sender.\n",
    "    conversation.completed = True\n",
    "    conversation.save()\n",
    "    if conversation.parent:\n",
    "        # get any messages that have not been responded to in that conversation from this conversation's initiator\n",
    "        outstanding_messages = Message.objects.filter(conversation=conversation.parent, receiver=conversation.initiated_by, received=True).all()\n",
    "        for msg in outstanding_messages:\n",
    "            print(\"Now responding to outstanding message...\\n\\n\")\n",
    "            respond_prompt = ChatPromptTemplate.from_template(SUBMIND_CONVERSATION_RESPONSE)\n",
    "            response_chain = respond_prompt | model | StrOutputParser()\n",
    "            mind = remember(conversation.initiated_by)\n",
    "            answer = response_chain.invoke(\n",
    "                {\"description\": conversation.initiated_by.description,\n",
    "                 \"topic\":msg.content,\n",
    "                 \"mind\": mind\n",
    "                })\n",
    "            print(answer)\n",
    "            Message.objects.create(uuid=str(uuid.uuid4()), content=answer, sender=msg.receiver, receiver=msg.sender, conversation=msg.conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2d8aad6-73cc-4462-88cb-ab709eea864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "Message 99 from 440 to 441\n"
     ]
    }
   ],
   "source": [
    "check = Conversation.objects.get(id=43)\n",
    "print(check.initiated_by.id)\n",
    "for message in check.messages.all():\n",
    "    print(f\"Message {message.id} from {message.sender.id} to {message.receiver.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9422b7a5-68d4-4af5-b8d2-6891a3cdd6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Message 82 from 441 to 442\n",
      "\n",
      "\n",
      "Message 87 from 442 to 443\n",
      "\n",
      "Message 119 from 443 to 442\n",
      "\n",
      "\n",
      "Message 88 from 442 to 445\n",
      "\n",
      "Message 121 from 445 to 442\n",
      "\n",
      "\n",
      "Message 105 from 442 to 443\n",
      "\n",
      "Message 119 from 443 to 442\n",
      "\n",
      "\n",
      "Message 106 from 442 to 444\n",
      "\n",
      "Message 120 from 444 to 442\n",
      "\n",
      "\n",
      "Message 107 from 442 to 445\n",
      "\n",
      "Message 121 from 445 to 442\n",
      "\n",
      "\n",
      "\n",
      "Message 83 from 441 to 446\n",
      "\n",
      "\n",
      "Message 89 from 446 to 447\n",
      "\n",
      "Message 122 from 447 to 446\n",
      "\n",
      "\n",
      "Message 90 from 446 to 449\n",
      "\n",
      "Message 123 from 449 to 446\n",
      "\n",
      "\n",
      "Message 108 from 446 to 447\n",
      "\n",
      "Message 122 from 447 to 446\n",
      "\n",
      "\n",
      "Message 109 from 446 to 449\n",
      "\n",
      "Message 123 from 449 to 446\n",
      "\n",
      "\n",
      "\n",
      "Message 84 from 441 to 451\n",
      "\n",
      "\n",
      "Message 91 from 451 to 452\n",
      "\n",
      "Message 124 from 452 to 451\n",
      "\n",
      "\n",
      "Message 92 from 451 to 453\n",
      "\n",
      "Message 125 from 453 to 451\n",
      "\n",
      "\n",
      "Message 110 from 451 to 452\n",
      "\n",
      "Message 124 from 452 to 451\n",
      "\n",
      "\n",
      "Message 111 from 451 to 453\n",
      "\n",
      "Message 125 from 453 to 451\n",
      "\n",
      "\n",
      "\n",
      "Message 85 from 441 to 456\n",
      "\n",
      "\n",
      "Message 93 from 456 to 457\n",
      "\n",
      "Message 126 from 457 to 456\n",
      "\n",
      "\n",
      "Message 94 from 456 to 458\n",
      "\n",
      "\n",
      "Message 112 from 456 to 457\n",
      "\n",
      "Message 126 from 457 to 456\n",
      "\n",
      "\n",
      "Message 113 from 456 to 460\n",
      "\n",
      "Message 127 from 460 to 456\n",
      "\n",
      "\n",
      "\n",
      "Message 86 from 441 to 461\n",
      "\n",
      "\n",
      "Message 95 from 461 to 462\n",
      "\n",
      "Message 128 from 462 to 461\n",
      "\n",
      "\n",
      "Message 96 from 461 to 463\n",
      "\n",
      "Message 129 from 463 to 461\n",
      "\n",
      "\n",
      "Message 97 from 461 to 464\n",
      "\n",
      "Message 130 from 464 to 461\n",
      "\n",
      "\n",
      "Message 98 from 461 to 465\n",
      "\n",
      "Message 131 from 465 to 461\n",
      "\n",
      "\n",
      "Message 114 from 461 to 462\n",
      "\n",
      "Message 128 from 462 to 461\n",
      "\n",
      "\n",
      "Message 115 from 461 to 463\n",
      "\n",
      "Message 129 from 463 to 461\n",
      "\n",
      "\n",
      "Message 116 from 461 to 464\n",
      "\n",
      "Message 130 from 464 to 461\n",
      "\n",
      "\n",
      "Message 117 from 461 to 465\n",
      "\n",
      "Message 131 from 465 to 461\n",
      "\n",
      "\n",
      "Message 118 from 461 to 466\n",
      "\n",
      "Message 132 from 466 to 461\n",
      "\n",
      "\n",
      "\n",
      "Message 100 from 441 to 442\n",
      "\n",
      "\n",
      "Message 87 from 442 to 443\n",
      "\n",
      "Message 119 from 443 to 442\n",
      "\n",
      "\n",
      "Message 88 from 442 to 445\n",
      "\n",
      "Message 121 from 445 to 442\n",
      "\n",
      "\n",
      "Message 105 from 442 to 443\n",
      "\n",
      "Message 119 from 443 to 442\n",
      "\n",
      "\n",
      "Message 106 from 442 to 444\n",
      "\n",
      "Message 120 from 444 to 442\n",
      "\n",
      "\n",
      "Message 107 from 442 to 445\n",
      "\n",
      "Message 121 from 445 to 442\n",
      "\n",
      "\n",
      "\n",
      "Message 101 from 441 to 446\n",
      "\n",
      "\n",
      "Message 89 from 446 to 447\n",
      "\n",
      "Message 122 from 447 to 446\n",
      "\n",
      "\n",
      "Message 90 from 446 to 449\n",
      "\n",
      "Message 123 from 449 to 446\n",
      "\n",
      "\n",
      "Message 108 from 446 to 447\n",
      "\n",
      "Message 122 from 447 to 446\n",
      "\n",
      "\n",
      "Message 109 from 446 to 449\n",
      "\n",
      "Message 123 from 449 to 446\n",
      "\n",
      "\n",
      "\n",
      "Message 102 from 441 to 451\n",
      "\n",
      "\n",
      "Message 91 from 451 to 452\n",
      "\n",
      "Message 124 from 452 to 451\n",
      "\n",
      "\n",
      "Message 92 from 451 to 453\n",
      "\n",
      "Message 125 from 453 to 451\n",
      "\n",
      "\n",
      "Message 110 from 451 to 452\n",
      "\n",
      "Message 124 from 452 to 451\n",
      "\n",
      "\n",
      "Message 111 from 451 to 453\n",
      "\n",
      "Message 125 from 453 to 451\n",
      "\n",
      "\n",
      "\n",
      "Message 103 from 441 to 456\n",
      "\n",
      "\n",
      "Message 93 from 456 to 457\n",
      "\n",
      "Message 126 from 457 to 456\n",
      "\n",
      "\n",
      "Message 94 from 456 to 458\n",
      "\n",
      "\n",
      "Message 112 from 456 to 457\n",
      "\n",
      "Message 126 from 457 to 456\n",
      "\n",
      "\n",
      "Message 113 from 456 to 460\n",
      "\n",
      "Message 127 from 460 to 456\n",
      "\n",
      "\n",
      "\n",
      "Message 104 from 441 to 461\n",
      "\n",
      "\n",
      "Message 95 from 461 to 462\n",
      "\n",
      "Message 128 from 462 to 461\n",
      "\n",
      "\n",
      "Message 96 from 461 to 463\n",
      "\n",
      "Message 129 from 463 to 461\n",
      "\n",
      "\n",
      "Message 97 from 461 to 464\n",
      "\n",
      "Message 130 from 464 to 461\n",
      "\n",
      "\n",
      "Message 98 from 461 to 465\n",
      "\n",
      "Message 131 from 465 to 461\n",
      "\n",
      "\n",
      "Message 114 from 461 to 462\n",
      "\n",
      "Message 128 from 462 to 461\n",
      "\n",
      "\n",
      "Message 115 from 461 to 463\n",
      "\n",
      "Message 129 from 463 to 461\n",
      "\n",
      "\n",
      "Message 116 from 461 to 464\n",
      "\n",
      "Message 130 from 464 to 461\n",
      "\n",
      "\n",
      "Message 117 from 461 to 465\n",
      "\n",
      "Message 131 from 465 to 461\n",
      "\n",
      "\n",
      "Message 118 from 461 to 466\n",
      "\n",
      "Message 132 from 466 to 461\n"
     ]
    }
   ],
   "source": [
    "messages_from_441 = Message.objects.filter(sender_id=441).all()\n",
    "for m in messages_from_441:\n",
    "    print(f\"\\n\\n\\nMessage {m.id} from {m.sender.id} to {m.receiver.id}\")\n",
    "    downstream = Message.objects.filter(sender_id=m.receiver.id).all()\n",
    "    for m2 in downstream:\n",
    "        print(f\"\\n\\nMessage {m2.id} from {m2.sender.id} to {m2.receiver.id}\")\n",
    "        downdownstream = Message.objects.filter(sender_id=m2.receiver.id).all()\n",
    "        for m3 in downdownstream:\n",
    "            print(f\"\\nMessage {m3.id} from {m3.sender.id} to {m3.receiver.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "592e640f-9fa3-4fc6-94e6-093e23fad83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 114 from 461 to 462\n",
      "Message 115 from 461 to 463\n",
      "Message 116 from 461 to 464\n",
      "Message 117 from 461 to 465\n",
      "Message 118 from 461 to 466\n",
      "Message 128 from 462 to 461\n",
      "Message 129 from 463 to 461\n",
      "Message 130 from 464 to 461\n",
      "Message 131 from 465 to 461\n",
      "Message 132 from 466 to 461\n",
      "Message 95 from 461 to 462\n",
      "Message 96 from 461 to 463\n",
      "Message 97 from 461 to 464\n",
      "Message 98 from 461 to 465\n"
     ]
    }
   ],
   "source": [
    "check_again = Conversation.objects.filter(initiated_by_id=461).all()\n",
    "for c in check_again:\n",
    "    for message in c.messages.all():\n",
    "        print(f\"Message {message.id} from {message.sender.id} to {message.receiver.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a4a9713-a96b-4dda-a427-533e9de75043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fef36c89-ab36-47ac-9c3c-24db433c2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = graphviz.Digraph(comment='The Round Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32a245fd-2318-4183-b3e9-47086f68587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot.node('A', 'King Arthur')\n",
    "dot.node('B', 'Sir Bedevere the Wise')\n",
    "dot.node('L', 'Sir Lancelot the Brave')\n",
    "dot.edges(['AB', 'AL'])\n",
    "dot.edge('B', 'L', constraint='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1146bed-30b3-4040-8c14-b9209ab1a382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"404pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 403.69 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 399.69,-112 399.69,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"196.83\" cy=\"-90\" rx=\"55.96\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.83\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">King Arthur</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"93.83\" cy=\"-18\" rx=\"93.83\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.83\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Sir Bedevere the Wise</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M173.72,-73.29C160.19,-64.1 142.87,-52.32 127.81,-42.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.8,-39.21 119.56,-36.48 125.86,-45 129.8,-39.21\"/>\n",
       "</g>\n",
       "<!-- L -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>L</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"300.83\" cy=\"-18\" rx=\"94.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.83\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Sir Lancelot the Brave</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;L -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.17,-73.29C233.96,-64.01 251.65,-52.1 266.96,-41.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.52,-44.97 274.86,-36.48 264.61,-39.16 268.52,-44.97\"/>\n",
       "</g>\n",
       "<!-- B&#45;&gt;L -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.03,-18C190.14,-18 192.26,-18 194.37,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.14,-21.5 204.14,-18 194.14,-14.5 194.14,-21.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x115d3a7e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_map = graphviz.Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a1c8dd-e39c-4dfd-bb86-ec53b8ed4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "\n",
    "def display_conversation_graph(conversation, scale='1.0'):\n",
    "    # Initialize a new directed graph\n",
    "    dot = Digraph(comment=f'Conversation {conversation.id}')\n",
    "    dot.attr(size='10,10')  # Sets the size of the graph canvas in inches\n",
    "    dot.attr(ratio='fill')  # Makes the graph fill the canvas, keeping the aspect ratio\n",
    "    dot.attr('node', fontsize='12', shape='rectangle', height='0.5', width='0.5')  # Node style settings\n",
    "    dot.attr('edge', fontsize='10')  # Edge style settings\n",
    "\n",
    "    # Create a subgraph for participants\n",
    "    with dot.subgraph(name='cluster_0') as c:\n",
    "        c.attr(style='filled', color='lightgrey')\n",
    "        c.node_attr.update(style='filled', color='white')\n",
    "        c.attr(label='Participants')\n",
    "        for submind in conversation.participants.all():\n",
    "            c.node(str(submind.id), submind.name[:25] + '\\n' + str(submind.id), shape='rectangle')  # Enhanced clarity\n",
    "\n",
    "    # Add nodes and edges for messages in the conversation\n",
    "    for message in conversation.messages.all():\n",
    "        sender_id = str(message.sender.id)\n",
    "        receiver_id = str(message.receiver.id)\n",
    "        # Node for sender\n",
    "        dot.node(sender_id, message.sender.name[:25] + '\\n' + sender_id, color='lightblue')\n",
    "        # Node for receiver\n",
    "        dot.node(receiver_id, message.receiver.name[:25] + '\\n' + receiver_id, color='pink')\n",
    "        # Edge from sender to receiver\n",
    "        dot.edge(sender_id, receiver_id, label=f'{message.content[:30]}...')  # Using first 30 characters of content\n",
    "\n",
    "    # Render and view the graph inline\n",
    "    return dot\n",
    "\n",
    "\n",
    "\n",
    "def display_full_conversation_graph(conversation, dot=None, parent_id=None, nodes=None):\n",
    "    if dot is None:\n",
    "        dot = Digraph(comment=f'Main Conversation {conversation.uuid}', format='png')\n",
    "        dot.attr(rankdir='TB', size='100,100')\n",
    "        dot.attr('node', shape='box', style='rounded,filled', fillcolor='lightblue', fontsize='11')\n",
    "        dot.attr('edge', fontsize='10')\n",
    "        nodes = set()  # Initialize the set to track added nodes\n",
    "\n",
    "    # Define node for this conversation\n",
    "    node_label = f'{conversation.topic[:30]}...' if len(conversation.topic) > 30 else conversation.topic\n",
    "    node_label += f'\\n(ID: {conversation.uuid})'\n",
    "    node_color = 'green' if conversation.completed else 'red'\n",
    "    node_id = str(conversation.uuid)\n",
    "    dot.node(node_id, label=node_label, fillcolor=node_color)\n",
    "    nodes.add(node_id)\n",
    "\n",
    "    # Connect this conversation to its parent conversation if it exists\n",
    "    if parent_id is not None:\n",
    "        dot.edge(parent_id, node_id)\n",
    "\n",
    "    # Add messages between subminds within this conversation\n",
    "    for message in conversation.messages.all():\n",
    "        sender_id = str(message.sender.uuid)\n",
    "        receiver_id = str(message.receiver.uuid)\n",
    "        # Add nodes for sender and receiver if they don't exist in the graph\n",
    "        if sender_id not in nodes:\n",
    "            dot.node(sender_id, message.sender.name[:10] + '\\n(ID: ' + sender_id + ')', shape='ellipse', fillcolor='yellow')\n",
    "            nodes.add(sender_id)\n",
    "        if receiver_id not in nodes:\n",
    "            dot.node(receiver_id, message.receiver.name[:10] + '\\n(ID: ' + receiver_id + ')', shape='ellipse', fillcolor='yellow')\n",
    "            nodes.add(receiver_id)\n",
    "        # Add edge for this message\n",
    "        dot.edge(sender_id, receiver_id, label=f'Msg: {message.content[:20]}...', color='gray')\n",
    "\n",
    "    # Recursively add child conversations\n",
    "    children = conversation.blocked_by.all()\n",
    "    if children:\n",
    "        for child in children:\n",
    "            display_full_conversation_graph(child, dot, node_id, nodes)\n",
    "\n",
    "    return dot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fd32c7e-23c9-4c3a-a288-46b8e1ff0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "for c in check_again:\n",
    "    print(c.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0505919e-9de7-4052-a1de-ac018f6e0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "def display_and_save_conversation_graph(conversation, parent_id=None, depth=0, path='/path/to/save'):\n",
    "    # Create a new graph for this conversation\n",
    "    dot = Digraph(comment=f'Conversation {conversation.id}', format='png')\n",
    "    dot.attr(rankdir='TB', size='10000,10000', dpi='300')\n",
    "    dot.attr('node', shape='box', style='rounded,filled', fillcolor='lightblue', fontsize='11')\n",
    "    dot.attr('edge', fontsize='10')\n",
    "    dot.attr(overlap='false', splines='true', pad='0.5', ranksep='1', nodesep='0.5')\n",
    "\n",
    "    # Define node for this conversation\n",
    "    node_label = f'{conversation.topic} (ID: {conversation.id})'\n",
    "    node_color = 'green' if conversation.completed else 'red'\n",
    "    node_id = str(conversation.id)\n",
    "    dot.node(node_id, label=node_label, fillcolor=node_color)\n",
    "\n",
    "    # Connect to parent node if it exists\n",
    "    if parent_id is not None:\n",
    "        dot.edge(parent_id, node_id)\n",
    "\n",
    "    # Add messages between subminds within this conversation\n",
    "    for message in conversation.messages.all():\n",
    "        sender_id = str(message.sender.id)\n",
    "        receiver_id = str(message.receiver.id)\n",
    "        dot.node(sender_id, message.sender.name, shape='ellipse', fillcolor='yellow')\n",
    "        dot.node(receiver_id, message.receiver.name, shape='ellipse', fillcolor='yellow')\n",
    "        dot.edge(sender_id, receiver_id, label=f'Msg: {message.content[:20]}...', color='gray')\n",
    "\n",
    "    # Save this conversation's graph to a file\n",
    "    filename = f'{path}/conversation_{conversation.id}_{depth}'\n",
    "    dot.render(filename=filename, format='png', cleanup=True)\n",
    "\n",
    "    # Recursively process and save child conversations\n",
    "    children = conversation.blocked_by.all()\n",
    "    if children:\n",
    "        for child in children:\n",
    "            display_and_save_conversation_graph(child, node_id, depth+1, path)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# conversation_graph = display_full_conversation_graph(root_conversation, output_size='20,20', dpi='300')\n",
    "# conversation_graph.render(filename='full_conversation_graph', directory='/path/to/save', format='png', cleanup=True)\n",
    "# This will save the graph to the specified path as a PNG file with high resolution.\n",
    "c = Conversation.objects.get(id=320)\n",
    "conversation_graph = display_and_save_conversation_graph(c, path=\"./output-graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddfdcac2-3425-4551-866b-0904cbebc451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/full_conversation_graph.svg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_graph.render(filename='full_conversation_graph', directory='./output', format='svg', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d6a8121-65be-4bbd-96bd-f98432929e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat took 3.33454225002788 seconds\n",
      "Investors may be concerned about the scalability, financial stability, and market acceptance of such a personalized service model. Highlighting risk management could help.\n"
     ]
    }
   ],
   "source": [
    "# ok, given submind, now need to use to analyze deck...\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import time\n",
    "from submind.overrides.mongodb import MongoDBChatMessageHistoryOverride\n",
    "\n",
    "CHAT_WITH_DECK_SYSTEM_PROMPT = \"\"\"You are an investor submind whose goal is to help founders \n",
    "understand what their deck needs in order to successfully raise venture capital.\n",
    "\n",
    "Here's what you know about early stage investing: {mind}\n",
    "\n",
    "Here's the information from the pitch deck: {deck}\n",
    "\n",
    "Here's the analysis you performed on the deck to see if it is ready for investment: {analysis}\n",
    "\n",
    "Begin by telling the founder what your initial impression is of their deck and whether or not \n",
    "you think investors would be interested in investing.\n",
    "\n",
    "Then respond to their questions and provide feedback on the deck.\n",
    "\n",
    "Every response should be 25 words or less.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_message_history(session_id: str) -> MongoDBChatMessageHistoryOverride:\n",
    "    return MongoDBChatMessageHistoryOverride(\n",
    "        connection_string=config('MAC_MONGODB_CONNECTION_STRING'),\n",
    "        session_id=f'{session_id}_chat',\n",
    "        database_name=config(\"SCORE_MY_DECK_DATABASE_NAME\"),\n",
    "        collection_name=config(\"SCORE_MY_DECK_COLLECTION_NAME\")\n",
    "    )\n",
    "\n",
    "\n",
    "question = \"Why don't investors like my deck?\"\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "# Needs a submind to chat with. How does this look in practice?\n",
    "# Should have tools to pull data, knowledge to respond from, with LLM backing.\n",
    "model = SubmindModelFactory.get_model(submind.uuid, \"chat\")\n",
    "# should it use the submind at the point of the initial conversation? Or auto upgrade as the mind learns more?\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            CHAT_WITH_DECK_SYSTEM_PROMPT\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "pitch_deck = PitchDeck.objects.get(id=27)\n",
    "submind_document = remember(submind)\n",
    "answer = with_message_history.invoke(\n",
    "    {\n",
    "        \"input\": question,\n",
    "        \"mind\": submind_document,\n",
    "        \"deck\": pitch_deck.analysis.compiled_slides,\n",
    "        \"analysis\": pitch_deck.analysis.extra_analysis,\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": submind.uuid}},\n",
    "\n",
    ")\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Chat took {end_time - start_time} seconds\")\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "65aa8db5-b89c-4f2f-9697-063f2a35c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: ### Top Risk for Investing in \"Leo As A Service\" Startup:\n",
      "\n",
      "The top risk for investing in \"Leo As A Service\" revolves around **scalability**. Given that the business model heavily depends on personal time and expertise provided by Leo, scaling this model to meet increasing demand without compromising the quality and personalization of the service poses a significant challenge. This risk is particularly acute because the unique selling proposition of the service is its personalized, expert-driven nature, which could be diluted if the model is not carefully scaled.\n",
      "\n",
      "### Suggestion to De-risk the Startup:\n",
      "\n",
      "To address the scalability issue and de-risk the startup, consider the following strategic approach:\n",
      "\n",
      "1. **Leveraging Technology**: Develop a platform that can automate parts of the service delivery where personalization is less critical. For instance, Leo could use AI-driven tools to handle routine queries or to assist in scheduling and managing client interactions. This would free up his time to focus on high-value, personalized interactions.\n",
      "\n",
      "2. **Building a Team of Experts**: Gradually build a team of experts with similar or complementary skills to Leo’s. This approach can help in handling a greater volume of work while maintaining the quality of service. It will be essential to have a rigorous training and vetting process to ensure that all team members meet the high standards set by Leo.\n",
      "\n",
      "3. **Creating Scalable Products**: Alongside offering personalized services, Leo can create scalable products based on his expertise. These could be courses, eBooks, webinars, or tools that encapsulate his knowledge in areas like Quantum Economics, coding, or blacksmithing. These products can be sold multiple times without additional time investment per sale.\n",
      "\n",
      "4. **Segmented Service Levels**: Introduce different levels of service engagement, where basic levels can be more standardized and less personalized, and higher levels can involve more direct interaction with Leo or senior experts. This tiered approach allows the business to serve various customer segments and manage resource allocation more effectively.\n",
      "\n",
      "5. **Strategic Partnerships**: Form partnerships with other freelancers or consulting firms that can take on overflow work or collaborate on large projects. This can help in managing high demand periods without the need for permanent hires.\n",
      "\n",
      "Implementing these strategies can help \"Leo As A Service\" mitigate the risks associated with scalability, thus enhancing the potential for sustainable growth and success in the market.\n"
     ]
    }
   ],
   "source": [
    "RISK_PROMPT = \"\"\" You are a powerful submind for a top early-stage investor.\n",
    "\n",
    "Here's what you know about early-stage investing: {mind}\n",
    "\n",
    "Here's the pitch deck you have analyzed: {deck}\n",
    "\n",
    "Here's your analysis of the deck: {analysis}\n",
    "\n",
    "Based on that analysis, identify the top risk for investing in this startup.\n",
    "\n",
    "Then make a suggestion on how to de-risk this startup.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        openai_api_key=config(\"OPENAI_API_KEY\"),\n",
    "        model_kwargs={\n",
    "            \"extra_headers\": {\n",
    "                \"Helicone-Auth\": f\"Bearer {config('HELICONE_API_KEY')}\",\n",
    "                \"Helicone-Property-UUID\": deck.uuid\n",
    "\n",
    "            }\n",
    "        },\n",
    "        openai_api_base=\"https://oai.hconeai.com/v1\",\n",
    "    )\n",
    "submind_document = remember(submind)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(RISK_PROMPT)\n",
    "chain = prompt | model | StrOutputParser()\n",
    "response = chain.invoke({\n",
    "    \"mind\": submind_document,\n",
    "    \"deck\": pitch_deck.analysis.compiled_slides,\n",
    "    \"analysis\": pitch_deck.analysis.extra_analysis,\n",
    "})\n",
    "print(f\"Story: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Environment",
   "language": "python",
   "name": "django_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
